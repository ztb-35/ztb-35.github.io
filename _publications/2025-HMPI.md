---
title: "Pruning and Malicious Injection: A Retraining-Free Backdoor Attack on Transformer Models"
collection: publications
category: arxiv
#permalink: /publication/2010-10-01-paper-title-number-2
#excerpt: 'This paper is about the number 2. The number 3 is left for future work.'
date: 2025-10-01
venue: 'arxiv preprint'
authors: 'Taibiao Zhao, Mingxuan Sun, Hao Wang, Xiangwei Zhou, Xiaobing Chen, Xugui Zhou'
#slidesurl: 'https://academicpages.github.io/files/slides2.pdf'
paperurl: 'https://arxiv.org/pdf/2508.10243?'
codeurl: 'https://github.com/ztb-35/HPMI'
#citation: 'Your Name, You. (2010). &quot;Paper Title Number 2.&quot; <i>Journal 1</i>. 1(2).'
---

<!-- Transformer models have demonstrated exceptional performance and have become indispensable in computer vision (CV) and natural language processing (NLP) tasks. However, recent studies reveal that transformers are susceptible to backdoor attacks. Prior backdoor attack methods typically rely on retraining with clean data or altering the model architecture, both of which can be resource-intensive and intrusive. In this paper, we propose Head-wise Pruning and Malicious Injection (HPMI), a novel retraining-free backdoor attack on transformers that does not alter the modelâ€™s architecture. Our approach requires only a small subset of the original data and basic knowledge of the model architecture, eliminating the need for retraining the target transformer. Technically, HPMI works by pruning the least important head and injecting a pre-trained malicious head to establish the backdoor. We provide a rigorous theoretical justification demonstrating that the implanted backdoor resists detection and removal by state-of-the-art defense techniques, under reasonable assumptions. Experimental evaluations across multiple datasets further validate the effectiveness of HPMI, showing that it 1) incurs negligible clean accuracy loss, 2) achieves at least 99.55% attack success rate, and 3) bypasses four advanced defense mechanisms. Additionally, relative to state-of-the-art retraining-dependent attacks, HPMI achieves greater concealment and robustness against diverse defense strategies, while maintaining minimal impact on clean accuracy. -->
